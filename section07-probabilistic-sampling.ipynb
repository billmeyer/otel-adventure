{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3806574f-0460-4be2-88ed-66bb7991ed63",
   "metadata": {},
   "source": [
    "# Sampling Traces using OpenTelemetry\n",
    "\n",
    "In this section, we will use the Trace example from Section 4 to create 100 traces and demonstrate how Probablistic and Tail-based Sampling works in OpenTelemetry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4491b-ff8b-4281-bbae-e45ce8353de2",
   "metadata": {},
   "source": [
    "## Probabilistic Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d1803-f972-431a-8b50-0eb3a27fb8a1",
   "metadata": {},
   "source": [
    "We'll start with Probabilistic Sampling (a.k.a., Head sampling). Head sampling is a sampling technique used to make a sampling decision as early as possible. A decision to sample or drop a span or trace is not made by inspecting the trace as a whole.\n",
    "\n",
    "For example, the most common form of head sampling is Consistent Probability Sampling. This is also be referred to as **Deterministic Sampling**. In this case, **a sampling decision is made based on the trace ID and the desired percentage of traces to sample**. This ensures that whole traces are sampled - no missing spans - at a consistent rate, such as 5% of all traces.\n",
    "\n",
    "The upsides to head sampling are:\n",
    "\n",
    "* Easy to understand\n",
    "* Easy to configure\n",
    "* Efficient\n",
    "* Can be done at any point in the trace collection pipeline\n",
    "\n",
    "**The primary downside to head sampling is that it is not possible to make a sampling decision based on data in the entire trace**. For example, you cannot ensure that all traces with an error within them are sampled with head sampling alone. For this situation and many others, you need tail sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e7991-e1fb-4a8e-a11b-d74803ce2365",
   "metadata": {},
   "source": [
    "## Modify the OpenTelemetry Collector config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674426dd-9ce2-432f-aefc-6d9166f07ec0",
   "metadata": {},
   "source": [
    "Here we will reconfigure our Collector to use the [Probabilistic Sampling Processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/probabilisticsamplerprocessor). This processor supports several modes of sampling for **spans** and **log records**. We will only focus on trace spans in this lab.\n",
    "\n",
    "For trace spans, this sampler supports probabilistic sampling based on **a configured sampling percentage applied to the TraceID**.\n",
    "\n",
    "1. Edit `config.yaml`, add `probabilistic_sampler` under the `processors` section:\n",
    "\n",
    "    ```yaml\n",
    "    processors:\n",
    "      probabilistic_sampler:\n",
    "        sampling_percentage: 15\n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "\n",
    "2. Include `probabilistic_sampler` in the `service.pipelines.traces.processors` section:\n",
    "\n",
    "    ```yaml\n",
    "        traces:\n",
    "          receivers: [otlp]\n",
    "          processors: [probabilistic_sampler, batch]\n",
    "          exporters: [debug/basic, datadog/connector, datadog]\n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "\n",
    "3. Save the config and restart the Collector.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9418455-3bb7-419c-9016-e2904f2cddec",
   "metadata": {},
   "source": [
    "## Import OpenTelemetry Modules for Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec279ac-32d8-4189-947c-f9d48601156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import baggage, trace\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import (\n",
    "    ConsoleSpanExporter,\n",
    "    BatchSpanProcessor\n",
    ")\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "import datetime, random, socket, time, uuid\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8467f2-8508-4073-865b-677532466832",
   "metadata": {},
   "source": [
    "## Create a **TracerProvider** that we can send trace spans to\n",
    "\n",
    "Create a [TraceProvider](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/api.md#tracerprovider) with some **Resource**-level [Semantic Attributes](https://github.com/open-telemetry/semantic-conventions/blob/main/docs/resource/README.md) that describe our service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d3c07-bb44-443d-97ea-356ddd32d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = TracerProvider(resource=Resource.create({\n",
    "    \"service.name\": __name__,\n",
    "    \"service.instance.id\": str(uuid.uuid4()),    \n",
    "    \"deployment.environment\": \"otel\",\n",
    "    \"host.name\": socket.gethostname(),\n",
    "    \"datadog.host.use_as_metadata\": True,\n",
    "}))\n",
    "print(provider._resource.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd0b28-032d-4e7e-b81f-a2592eebdf8a",
   "metadata": {},
   "source": [
    "## Get a **Tracer** from the **TracerProvider**\n",
    "\n",
    "Next we create a [BatchSpanProcessor](https://opentelemetry-python.readthedocs.io/en/latest/sdk/trace.export.html#opentelemetry.sdk.trace.export.BatchSpanProcessor) that uses an [OTLPSpanExporter](https://opentelemetry-python.readthedocs.io/en/latest/exporter/otlp/otlp.html#opentelemetry.exporter.otlp.proto.grpc.trace_exporter.OTLPSpanExporter) that is used to send the span to our OTEL Collector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b97a58c-39a1-4c42-bef2-27c7fce0ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider.add_span_processor(BatchSpanProcessor(OTLPSpanExporter(endpoint=\"localhost:4317\", insecure=True)))\n",
    "tracer = trace.get_tracer(\"python\", tracer_provider=provider)\n",
    "print(tracer.resource.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d44f23b-adcd-4885-9ff8-16de9789c01b",
   "metadata": {},
   "source": [
    "## Create a new trace span and send it to the collector\n",
    "\n",
    "With the **Tracer**, we can finally start emitting spans. This simple example create a parent span and a child span simulating one microservice invoking another service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0fcc14-a297-44af-9e3b-02be798cc61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTracer(service_name):\n",
    "    provider = TracerProvider(resource=Resource.create({\n",
    "        \"service.name\": service_name,\n",
    "        \"service.instance.id\": str(uuid.uuid4()),        \n",
    "        \"deployment.environment\": \"otel\",\n",
    "        \"host.name\": socket.gethostname(),\n",
    "        \"datadog.host.use_as_metadata\": True,\n",
    "    }))\n",
    "    provider.add_span_processor(BatchSpanProcessor(OTLPSpanExporter(endpoint=\"localhost:4317\", insecure=True)))\n",
    "    return trace.get_tracer(\"python\", tracer_provider=provider)\n",
    "    \n",
    "def frontend():\n",
    "    frontend_tracer = getTracer(\"frontend\")\n",
    "    with frontend_tracer.start_as_current_span(\"frontend\") as frontend_span:\n",
    "        handle_checkout()\n",
    "        frontend_span.set_status(Status(StatusCode.OK))\n",
    "\n",
    "def handle_checkout():\n",
    "    checkout_tracer = getTracer(\"checkout\")\n",
    "    with checkout_tracer.start_as_current_span(\"checkout\") as checkout_span:\n",
    "        checkout_span.set_attribute(\"order_num\", int(datetime.datetime.timestamp(datetime.datetime.now())*1000) % 100000)\n",
    "        handle_payment()\n",
    "        handle_shipping()\n",
    "        checkout_span.set_status(Status(StatusCode.OK))\n",
    "        \n",
    "def handle_payment():\n",
    "    payment_tracer = getTracer(\"payment\")\n",
    "    with payment_tracer.start_as_current_span(\"payment\") as payment_span:\n",
    "        payment_span.set_attribute(\"payment_id\", str(uuid.uuid4()))\n",
    "        if (random.random() < 0.1):\n",
    "            payment_span.set_status(Status(StatusCode.ERROR))\n",
    "        else:\n",
    "            time.sleep(random.random())\n",
    "            payment_span.set_status(Status(StatusCode.OK))\n",
    "    \n",
    "def handle_shipping():\n",
    "    shipping_tracer = getTracer(\"shipping\")\n",
    "    with shipping_tracer.start_as_current_span(\"shipping\") as shipping_span:\n",
    "        shipping_span.set_attribute(\"tracking_num\", str(uuid.uuid4()))\n",
    "\n",
    "for n in tqdm(range(100)):\n",
    "    frontend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6de10a-b93e-40a6-9ee9-b07b9d6b6878",
   "metadata": {},
   "source": [
    "## Verify Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c90b7-d086-40bc-99f4-7b85a3922c86",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>DID IT WORK???</div>\n",
    "\n",
    "### How can we verify results?\n",
    "\n",
    "### probablistic_sampler metrics\n",
    "\n",
    "Open the [documentation](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/probabilisticsamplerprocessor/documentation.md) for the `probabilistic_sampler` processor.\n",
    "\n",
    "There are two metrics emitted by this processor:\n",
    "\n",
    "* `otelcol_processor_probabilistic_sampler_count_logs_sampled`\n",
    "* `otelcol_processor_probabilistic_sampler_count_traces_sampled`\n",
    "\n",
    "We'll focus on the second one for traces. To view the metric, we'll look at the `telemetry` service we have configured in the Collector to understand the Collector's runtime metrics.\n",
    "\n",
    "### Review the Collector metrics\n",
    "\n",
    "1. Open [http://localhost:8888/metrics](http://localhost:8888/metrics)\n",
    "\n",
    "2. Search the web page for the metric name: `otelcol_processor_probabilistic_sampler_count_traces_sampled`. There should be two instances of the same metric, one with a label named `sampled=\"false\"` and one with a label named `sampled=\"true\"`:\n",
    "\n",
    "    ```\n",
    "    # HELP otelcol_processor_probabilistic_sampler_count_traces_sampled Count of traces that were sampled or not\n",
    "    # TYPE otelcol_processor_probabilistic_sampler_count_traces_sampled counter\n",
    "    otelcol_processor_probabilistic_sampler_count_traces_sampled{policy=\"trace_id_w3c\",sampled=\"false\",service_instance_id=\"47f5a485-cd3a-4626-8c69-530946b01729\",service_name=\"otelcol-contrib\",service_version=\"0.112.0\"} 344\n",
    "    otelcol_processor_probabilistic_sampler_count_traces_sampled{policy=\"trace_id_w3c\",sampled=\"true\",service_instance_id=\"47f5a485-cd3a-4626-8c69-530946b01729\",service_name=\"otelcol-contrib\",service_version=\"0.112.0\"} 56\n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "\n",
    "    The instance where `sampled=\"false\"` shows the number of trace spans that were *dropped*. `sampled=\"true\"` are the spans that were allowed to pass to the output of the processor.\n",
    "\n",
    "    In the above example, if we add `344` and `56` we get the `400` spans we initially sent. `(56 / 400) * 100%` gives us 14% which is close to our configured number of `15`.\n",
    "\n",
    "    <div class=\"alert alert-block alert-info\">NOTE: As more spans are sent, the number does converge on that configured value specified.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f71ebd-5e35-4a66-852a-04704f3593cb",
   "metadata": {},
   "source": [
    "#### End of Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a34014-1305-438b-81cf-35567e7200a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
