{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3806574f-0460-4be2-88ed-66bb7991ed63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Sampling Traces using OpenTelemetry\n",
    "\n",
    "In this section, we will use the Trace example from Section 4 to create 100 traces and demonstrate how Probablistic and Tail-based Sampling works in OpenTelemetry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4491b-ff8b-4281-bbae-e45ce8353de2",
   "metadata": {},
   "source": [
    "## Probabilistic Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d1803-f972-431a-8b50-0eb3a27fb8a1",
   "metadata": {},
   "source": [
    "We'll start with Probabilistic Sampling (a.k.a., Head sampling). Head sampling is a sampling technique used to make a sampling decision as early as possible. A decision to sample or drop a span or trace is not made by inspecting the trace as a whole.\n",
    "\n",
    "For example, the most common form of head sampling is Consistent Probability Sampling. This is also be referred to as **Deterministic Sampling**. In this case, **a sampling decision is made based on the trace ID and the desired percentage of traces to sample**. This ensures that whole traces are sampled - no missing spans - at a consistent rate, such as 5% of all traces.\n",
    "\n",
    "The upsides to head sampling are:\n",
    "\n",
    "* Easy to understand\n",
    "* Easy to configure\n",
    "* Efficient\n",
    "* Can be done at any point in the trace collection pipeline\n",
    "\n",
    "**The primary downside to head sampling is that it is not possible to make a sampling decision based on data in the entire trace**. For example, you cannot ensure that all traces with an error within them are sampled with head sampling alone. For this situation and many others, you need tail sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e7991-e1fb-4a8e-a11b-d74803ce2365",
   "metadata": {},
   "source": [
    "## Modify the OpenTelemetry Collector config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674426dd-9ce2-432f-aefc-6d9166f07ec0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Here we will reconfigure our Collector to use the [Probabilistic Sampling Processor](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/probabilisticsamplerprocessor). This processor supports several modes of sampling for **spans** and **log records**. We will only focus on trace spans in this lab.\n",
    "\n",
    "For trace spans, this sampler supports probabilistic sampling based on **a configured sampling percentage applied to the TraceID**.\n",
    "\n",
    "1. Edit `config.yaml`, add `probabilistic_sampler` under the `processors` section:\n",
    "\n",
    "    ```yaml\n",
    "    processors:\n",
    "      probabilistic_sampler:\n",
    "        sampling_percentage: 15\n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "\n",
    "2. Include `probabilistic_sampler` in the `service.pipelines.traces.processors` section:\n",
    "\n",
    "    ```yaml\n",
    "        traces:\n",
    "          receivers: [otlp]\n",
    "          processors: [probabilistic_sampler, batch]\n",
    "          exporters: [debug/basic, datadog/connector, datadog]\n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "\n",
    "3. Save the config and restart the Collector.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9418455-3bb7-419c-9016-e2904f2cddec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Import OpenTelemetry Modules for Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec279ac-32d8-4189-947c-f9d48601156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import baggage, trace\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import (\n",
    "    ConsoleSpanExporter,\n",
    "    BatchSpanProcessor\n",
    ")\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "import datetime, random, socket, time, uuid\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d44f23b-adcd-4885-9ff8-16de9789c01b",
   "metadata": {},
   "source": [
    "## Send Traces to the Collector\n",
    "\n",
    "We'll reuse the same example from Section 4 for sending traces, this time sending 100 traces instead of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0fcc14-a297-44af-9e3b-02be798cc61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTracer(service_name):\n",
    "    provider = TracerProvider(resource=Resource.create({\n",
    "        \"service.name\": service_name,\n",
    "        \"service.instance.id\": str(uuid.uuid4()),        \n",
    "        \"deployment.environment.name\": \"otel-adventure\",\n",
    "        \"host.name\": socket.gethostname(),\n",
    "    }))\n",
    "    provider.add_span_processor(BatchSpanProcessor(OTLPSpanExporter(endpoint=\"localhost:4317\", insecure=True)))\n",
    "    return trace.get_tracer(\"python\", tracer_provider=provider)\n",
    "    \n",
    "def frontend():\n",
    "    frontend_tracer = getTracer(\"frontend\")\n",
    "    with frontend_tracer.start_as_current_span(\"frontend\") as frontend_span:\n",
    "        handle_checkout()\n",
    "        frontend_span.set_status(Status(StatusCode.OK))\n",
    "\n",
    "def handle_checkout():\n",
    "    checkout_tracer = getTracer(\"checkout\")\n",
    "    with checkout_tracer.start_as_current_span(\"checkout\") as checkout_span:\n",
    "        checkout_span.set_attribute(\"order_num\", int(datetime.datetime.timestamp(datetime.datetime.now())*1000) % 100000)\n",
    "        handle_payment()\n",
    "        handle_shipping()\n",
    "        checkout_span.set_status(Status(StatusCode.OK))\n",
    "        \n",
    "def handle_payment():\n",
    "    payment_tracer = getTracer(\"payment\")\n",
    "    with payment_tracer.start_as_current_span(\"payment\") as payment_span:\n",
    "        payment_span.set_attribute(\"payment_id\", str(uuid.uuid4()))\n",
    "        if (random.random() < 0.1):\n",
    "            payment_span.set_status(Status(StatusCode.ERROR))\n",
    "        else:\n",
    "            time.sleep(random.random())\n",
    "            payment_span.set_status(Status(StatusCode.OK))\n",
    "    \n",
    "def handle_shipping():\n",
    "    shipping_tracer = getTracer(\"shipping\")\n",
    "    with shipping_tracer.start_as_current_span(\"shipping\") as shipping_span:\n",
    "        shipping_span.set_attribute(\"tracking_num\", str(uuid.uuid4()))\n",
    "\n",
    "for n in tqdm(range(100)):\n",
    "    frontend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6de10a-b93e-40a6-9ee9-b07b9d6b6878",
   "metadata": {},
   "source": [
    "## Verify Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad774b-c66b-4b71-b5ee-eb70fe84a624",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>DID IT WORK???</div>\n",
    "    \n",
    "Recall that we configured the **Probablistic Sampler Processor** to sample 15%. As such, we'd expect 15 traces to be sampled and sent to Datadog, the other 85% should have been dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ec64b-9b0c-488e-ade7-da5e72929059",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d61c0bad-66cc-4f76-9eee-cb8e2bfc2f98",
   "metadata": {},
   "source": [
    "### How can we verify results?\n",
    "\n",
    "#### probablistic_sampler metrics\n",
    "\n",
    "Open the [documentation](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/probabilisticsamplerprocessor/documentation.md) for the `probabilistic_sampler` processor.\n",
    "\n",
    "There are two metrics emitted by this processor, one for **logs** and one for **traces**:\n",
    "\n",
    "* `otelcol_processor_probabilistic_sampler_count_logs_sampled`\n",
    "* `otelcol_processor_probabilistic_sampler_count_traces_sampled`\n",
    "\n",
    "We'll focus on the second one for **traces**.\n",
    "\n",
    "To access these metrics, we already have the `telemetry` service configured in our Collector:\n",
    "\n",
    "```yaml\n",
    "service:\n",
    "  telemetry:\n",
    "    metrics:\n",
    "      readers:\n",
    "        - pull:\n",
    "            exporter:\n",
    "              prometheus:\n",
    "                host: \"localhost\"\n",
    "                port: 8888\n",
    "```\n",
    "\n",
    "Note that it's listening on `localhost:8888`. This service will provide **tons** of insight related to the current health of the Collector's runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368d18f-2cfa-45ff-90d8-8bf0ef327036",
   "metadata": {},
   "source": [
    "### Review the Collector metrics\n",
    "\n",
    "1. Open the Collector's metrics endpoint: [http://localhost:8888/metrics](http://localhost:8888/metrics) \n",
    "\n",
    "2. Search the web page for the metric name: `otelcol_processor_probabilistic_sampler_count_traces_sampled`.\n",
    "\n",
    "   There should be two instances of the same metric: one with a **label** named `sampled=\"false\"` and one with a **label** named `sampled=\"true\"`:\n",
    "\n",
    "    ```\n",
    "    # HELP otelcol_processor_probabilistic_sampler_count_traces_sampled Count of traces that were sampled or not\n",
    "    # TYPE otelcol_processor_probabilistic_sampler_count_traces_sampled counter\n",
    "    otelcol_processor_probabilistic_sampler_count_traces_sampled{policy=\"trace_id_w3c\",sampled=\"false\",service_instance_id=\"47f5a485-cd3a-4626-8c69-530946b01729\",service_name=\"otelcol-contrib\",service_version=\"0.112.0\"} 344\n",
    "    otelcol_processor_probabilistic_sampler_count_traces_sampled{policy=\"trace_id_w3c\",sampled=\"true\",service_instance_id=\"47f5a485-cd3a-4626-8c69-530946b01729\",service_name=\"otelcol-contrib\",service_version=\"0.112.0\"} 56\n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "\n",
    "    The instance where `sampled=\"false\"` shows the number of trace spans that were *dropped*. `sampled=\"true\"` are the spans that were allowed to pass to the output of the processor.\n",
    "\n",
    "    In the above example, if we add `344` and `56` we get the `400` spans we initially sent. `(56 / 400) * 100%` gives us 14% which is close to our configured number of `15`.\n",
    "\n",
    "    <div class=\"alert alert-block alert-info\">NOTE: As more spans are sent, the number does converge on that configured value specified.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f71ebd-5e35-4a66-852a-04704f3593cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### End of Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a34014-1305-438b-81cf-35567e7200a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
